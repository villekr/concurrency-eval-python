name: CI

on:
  pull_request:
    # Temporarily run on any PR changes to test CI
    types: [opened, synchronize, reopened, ready_for_review]
  push:
    # Temporarily run on pushes to any branch to test CI
    branches: ['**']

jobs:
  lint:
    name: Ruff format and lint
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install ruff
        run: |
          python -m pip install --upgrade pip
          pip install ruff

      - name: Ruff format check (src)
        run: ruff format --check src

      - name: Ruff lint (src)
        run: ruff check src

  package-and-upload:
    name: Package Lambda and upload artifacts to S3
    needs: lint
    if: github.event_name == 'push'
    runs-on: ubuntu-latest
    permissions:
      id-token: write   # required for GitHub OIDC
      contents: read
    env:
      ARTIFACT_BUCKET_NAME: ${{ vars.ARTIFACT_BUCKET_NAME || secrets.ARTIFACT_BUCKET_NAME }}
      WRITER_ROLE_ARN: ${{ vars.WRITER_ROLE_ARN || secrets.WRITER_ROLE_ARN }}
      AWS_REGION: ${{ vars.AWS_REGION || secrets.AWS_REGION }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Validate required configuration
        shell: bash
        run: |
          set -euo pipefail
          : "${ARTIFACT_BUCKET_NAME?Define ARTIFACT_BUCKET_NAME as a Repository/Environment variable or Secret}"
          : "${WRITER_ROLE_ARN?Define WRITER_ROLE_ARN as a Repository/Environment variable or Secret}"
          : "${AWS_REGION?Define AWS_REGION as a Repository/Environment variable or Secret}"

      - name: Compute artifact metadata (name/version/date/sha)
        id: meta
        shell: bash
        run: |
          python - <<'PY' >> "$GITHUB_OUTPUT"
          import tomllib, pathlib, os, datetime
          data = tomllib.loads(pathlib.Path('pyproject.toml').read_text())
          name = data.get('project', {}).get('name', 'app')
          version = data.get('project', {}).get('version', '0.0.0')
          sha = os.getenv('GITHUB_SHA','')[:7]
          date = datetime.datetime.utcnow().strftime('%Y%m%d')
          print(f"name={name}")
          print(f"version={version}")
          print(f"sha={sha}")
          print(f"date={date}")
          print(f"base_prefix={name}/{version}/{date}/{sha}")
          PY

      - name: Set up uv
        uses: astral-sh/setup-uv@v4

      - name: Export dependencies to requirements.txt from uv.lock
        run: uv export --frozen --no-dev -o requirements.txt

      - name: Prepare Lambda layer (Python dependencies)
        run: |
          set -euxo pipefail
          mkdir -p build/layer/python
          # If requirements.txt exists, install deps into layer; otherwise create an empty layer structure
          if [ -f requirements.txt ]; then
            python -m pip install --upgrade pip
            pip install -r requirements.txt -t build/layer/python
          else
            echo "No requirements.txt found; building an empty layer (stdlib-only)."
          fi
          (cd build/layer && zip -r ../layer.zip .)

      - name: Package Lambda function code
        run: |
          set -euxo pipefail
          mkdir -p build/function
          cp src/lambda_function.py build/function/
          (cd build/function && zip -r ../function.zip .)

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.WRITER_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: github-actions-artifact-upload

      - name: Upload artifacts to S3
        env:
          BUCKET: ${{ env.ARTIFACT_BUCKET_NAME }}
        run: |
          set -euxo pipefail
          BASE="${{ steps.meta.outputs.base_prefix }}"
          LAYER_KEY="lambda-layer/${BASE}.zip"
          FUNC_KEY="lambda-function/${BASE}.zip"
          aws s3 cp build/layer.zip "s3://${BUCKET}/${LAYER_KEY}"
          aws s3 cp build/function.zip "s3://${BUCKET}/${FUNC_KEY}"
          echo "layer_s3_uri=s3://${BUCKET}/${LAYER_KEY}" >> "$GITHUB_OUTPUT"
          echo "function_s3_uri=s3://${BUCKET}/${FUNC_KEY}" >> "$GITHUB_OUTPUT"

      - name: Summary
        run: |
          echo "Artifacts uploaded:" >> $GITHUB_STEP_SUMMARY
          echo "- Layer: s3://${{ env.ARTIFACT_BUCKET_NAME }}/lambda-layer/${{ steps.meta.outputs.base_prefix }}.zip" >> $GITHUB_STEP_SUMMARY
          echo "- Function: s3://${{ env.ARTIFACT_BUCKET_NAME }}/lambda-function/${{ steps.meta.outputs.base_prefix }}.zip" >> $GITHUB_STEP_SUMMARY
